
# ğŸ§ Transcript Processor â€“ Audio to text file with Topics

This project allows you to:

1. ğŸ“ Transcribe audio files (e.g., university lectures) using Azure OpenAI.
2. ğŸ“š Process the transcription to generate a Markdown document organized into topic sections.

---

## ğŸ“ Project structure

```
.
â”œâ”€â”€ app.py                         # Orchestrator: transcription + processing
â”œâ”€â”€ transcriptor.py                # Script for audio transcription
â”œâ”€â”€ process.py       # Script to process the transcription
â”œâ”€â”€ requirements.txt               # Python dependencies

```

## âš™ï¸ Requirements

- Python 3.8+
- Azure OpenAI account with access to:
    - transcription model  (e.g., gpt-4o-audio-preview)
    - GPT completion model (e.g., GPT-4 or GPT-3.5)
- Audio files (e.g., `.mp3`, `.m4a`, etc.)


## ğŸ“¦ Installation

1. Create a virtual environment (optional but recommended):

     ```
     ./start.sh
     ```

3. Create a `.env` file in the project root with the following content:

     ```env
     AZURE_OPENAI_KEY="your_api_key"
     AZURE_OPENAI_STT_ENDPOINT="https://.../audio/transcriptions?api-version=..."
     AZURE_OPENAI_ENDPOINT="https://...azure.com/"
     AZURE_OPENAI_STT_MODEL="transcription_model_name"
     AZURE_OPENAI_COMPLETION_MODEL="gpt_model_name"
     AZURE_OPENAI_API_VERSION="2024-12-01-preview"

     INPUT_FOLDER="/path/to/your/audio"
     OUTPUT_FOLDER="/path/to/output"
     EXTENSION_OUTPUT_TRANSCRIPTION=".md"
     CHUNK_LENGTH_MS="300000"  # e.g., 5 minutes
     ```


## Usage

### ğŸ” Full run (transcription + segmentation)

```bash
python app.py filename.mp3
```

Output:

* `filename.md` â†’ raw transcription
* `filename_withTopics.md` â†’ segmented version with topic sections

### ğŸ“ Transcription only

```bash
python transcriptor.py filename.mp3
```

### ğŸ“š Process transcription only

```bash
python process.py filename.md
```

## Notes

* Files are automatically saved to the folder specified in `.env`.
* Each audio chunk is sent separately to OpenAI STT.
    * Currently audio models have a limit of about 20 minutes.
    * If the audio to transcribe is shorter than this limit, you can use `transcriptor.sh` directly.
* The resulting transcription is passed to GPT to organize the content into coherent topic sections.

